{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f95d506-b911-4dc4-bdf2-e181205373a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Tensorflow Dataloader Profiling\n",
    "Swapping to TF I/O."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34866e3f-8ec2-4b7b-a51a-eb9032a4d755",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This notebook moves image loading into tf.io.read_file which is threadsafe. Changes:\n",
    "- Move from CV2 to TF.image_read\n",
    "- Replace OpenCV with TensorFlow's image processing functions to leverage GPU acceleration\n",
    "- Increase shuffle buffer size\n",
    "- Reduce the prefetch size to 3 instead of AutoTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "789a7c9e-d53f-4fb6-aa08-a8a6c8532952",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Some quality of life fixes for logging\n",
    "import os\n",
    "import urllib3\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "urllib3.connection.HTTPConnection.default_pool_maxsize = 50\n",
    "urllib3.connection.HTTPSConnection.default_pool_maxsize = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "644b4114-363a-4094-a06e-b94c0b64b618",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bad1a54d-854c-450e-8a8f-e3087fddec41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Same function but now we use Tensorflow IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92f33a82-fe74-4fea-abd7-99ca846ccf6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset(\n",
    "    image_paths: list, \n",
    "    batch_size: int = 32, \n",
    "    img_shape=(224, 224), \n",
    "    max_objects=30,\n",
    "    use_random=True):\n",
    "    \"\"\"Creates a dataset from a list of image paths with optimized performance using TensorFlow IO\"\"\"\n",
    "    \n",
    "    # Create dataset from tensor slices for better performance\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    \n",
    "    if use_random:\n",
    "        # Use a larger buffer for better randomization, but not too large to avoid memory issues\n",
    "        buffer_size = min(len(image_paths), 10000)\n",
    "        dataset = dataset.shuffle(\n",
    "            buffer_size=buffer_size, \n",
    "            reshuffle_each_iteration=True\n",
    "            )\n",
    "    \n",
    "    # Cache file paths before expensive operations\n",
    "    dataset = dataset.cache()\n",
    "    \n",
    "    def _load_image(image_path):\n",
    "        \"\"\"\n",
    "        Load image using TensorFlow operations\n",
    "        Do TensorFlow operations seperately\n",
    "        \"\"\"\n",
    "        img_data = tf.io.read_file(image_path)\n",
    "        img = tf.io.decode_png(img_data, channels=3)\n",
    "        img = tf.image.resize(img, img_shape)\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        return img\n",
    "    \n",
    "    def _load_annotation(image_path_tensor):\n",
    "        \"\"\"\n",
    "        Python function to load annotations\n",
    "        JSON parsing is not available in TF ops\n",
    "        Needs a py_function\n",
    "        \"\"\"\n",
    "        image_path = image_path_tensor.numpy().decode('utf-8')\n",
    "        annotation_path = image_path.replace('.png', '.json')\n",
    "        with open(annotation_path, 'r') as f:\n",
    "            ann = json.load(f)\n",
    "        \n",
    "        bboxes = np.array(ann['objects']['bbox'], dtype=np.float32)\n",
    "        categories = np.array(ann['objects']['category'], dtype=np.int32)\n",
    "        \n",
    "        # Pad bboxes and categories\n",
    "        padded_bboxes = np.zeros((max_objects, 4), dtype=np.float32)\n",
    "        padded_categories = np.full((max_objects), -1, dtype=np.int32)\n",
    "        \n",
    "        num_objects = min(len(bboxes), max_objects)\n",
    "        padded_bboxes[:num_objects] = bboxes[:num_objects]\n",
    "        padded_categories[:num_objects] = categories[:num_objects]\n",
    "        \n",
    "        return padded_bboxes, padded_categories\n",
    "    \n",
    "    def _process_path(image_path):\n",
    "        \"\"\"Process a single image path\"\"\"\n",
    "        image = _load_image(image_path)\n",
    "\n",
    "        bboxes, categories = tf.py_function(\n",
    "            _load_annotation,\n",
    "            [image_path],\n",
    "            [tf.float32, tf.int32]\n",
    "        )\n",
    "        \n",
    "        image = tf.ensure_shape(image, (img_shape[0], img_shape[1], 3))\n",
    "        bboxes_out = tf.ensure_shape(bboxes, (max_objects, 4))\n",
    "        categories_out = tf.ensure_shape(categories, (max_objects,))\n",
    "\n",
    "        return {'images': tf.cast(image, tf.float32, name='images')}, {\n",
    "            'bboxes': tf.cast(bboxes_out, tf.float32, name='bboxes'),\n",
    "            'classes': tf.cast(categories_out, tf.int32, name='classes')\n",
    "        }\n",
    "    \n",
    "    dataset = dataset.map(_process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cd4e217-9a80-4e83-a989-35cea2205180",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "image_paths = [str(x) for x in Path('/Volumes/shm/default/cppe5/').glob('*.png')]\n",
    "dataset = create_dataset(image_paths[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41cd371a-80c0-43fb-8cc7-8aedd53d06ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for batch in dataset.take(1):\n",
    "    images = batch[0]['images']\n",
    "    bboxes = batch[1]['bboxes']\n",
    "    categories = batch[1]['classes']\n",
    "    print(f\"Input shape: {images.shape}\")\n",
    "    print(f\"Bounding boxes shape: {bboxes.shape}\")\n",
    "    print(f\"Categories shape: {categories.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89a11401-1f3c-4d75-b82a-df33abae86f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from model import build_object_detection_model\n",
    "model = build_object_detection_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f4cb66e-dd00-46b7-8cb2-e692a14eb0b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Same steps per epoch, but now we are using the Tensorflow I/O dataset. The libpng warning dissapear. This seems to reduce data loading on the GPU significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00378b67-6135-4fe7-ada4-885dfd8fb7e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = len(image_paths) // 32\n",
    "model.fit(dataset, epochs=1, steps_per_epoch=steps_per_epoch)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02_cppe_dataloader_tfio.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
