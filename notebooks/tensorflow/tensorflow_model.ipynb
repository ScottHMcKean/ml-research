{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = '../data/cppe5'\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "MAX_OBJECTS = 20\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"\n",
    "    Create a custom CNN model for object detection\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    \n",
    "    # Feature extraction layers\n",
    "    x = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D()(x)\n",
    "    \n",
    "    # Flatten and dense layers\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    # For each potential object: 4 bbox coords + num_classes + 1 objectness score\n",
    "    output_size = MAX_OBJECTS * (4 + NUM_CLASSES + 1)\n",
    "    outputs = tf.keras.layers.Dense(output_size)(x)\n",
    "    outputs = tf.keras.layers.Reshape((MAX_OBJECTS, 4 + NUM_CLASSES + 1))(outputs)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotation(annotation):\n",
    "    \"\"\"\n",
    "    Parse COCO format annotations [x_min, y_min, width, height]\n",
    "    and normalize to [0, 1] scale\n",
    "    \"\"\"\n",
    "    boxes = np.zeros((MAX_OBJECTS, 4))\n",
    "    classes = np.zeros(MAX_OBJECTS)\n",
    "    mask = np.zeros(MAX_OBJECTS)\n",
    "    \n",
    "    for idx, _ in enumerate(annotation['objects']['id']):\n",
    "        if idx >= MAX_OBJECTS:\n",
    "            break\n",
    "            \n",
    "        # Get COCO format bbox\n",
    "        x_min, y_min, width, height = annotation['objects']['bbox'][idx]\n",
    "        \n",
    "        # Convert to normalized coordinates [x_min, y_min, x_max, y_max]\n",
    "        x_min_norm = x_min / annotation['width']\n",
    "        y_min_norm = y_min / annotation['height']\n",
    "        x_max_norm = (x_min + width) / annotation['width']\n",
    "        y_max_norm = (y_min + height) / annotation['height']\n",
    "        \n",
    "        # Clip values to [0, 1]\n",
    "        x_min_norm = np.clip(x_min_norm, 0, 1)\n",
    "        y_min_norm = np.clip(y_min_norm, 0, 1)\n",
    "        x_max_norm = np.clip(x_max_norm, 0, 1)\n",
    "        y_max_norm = np.clip(y_max_norm, 0, 1)\n",
    "        \n",
    "        boxes[idx] = [x_min_norm, y_min_norm, x_max_norm, y_max_norm]\n",
    "        classes[idx] = annotation['objects']['category'][idx]\n",
    "        mask[idx] = 1\n",
    "    \n",
    "    return boxes, classes, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetectionDataset:\n",
    "    def __init__(self, image_dir, batch_size=16):\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def load_data(self):\n",
    "        images = []\n",
    "        all_boxes = []\n",
    "        all_classes = []\n",
    "        all_masks = []\n",
    "        \n",
    "        for img_file in os.listdir(self.image_dir):\n",
    "            if img_file.endswith('.png'):\n",
    "                \n",
    "                # Load image and get original dimensions\n",
    "                img_path = os.path.join(self.image_dir, img_file)\n",
    "                img = Image.open(img_path)\n",
    "                \n",
    "                # Convert to RGB if not already\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                \n",
    "                # Resize image\n",
    "                img = img.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "                img_array = np.array(img) / 255.0\n",
    "                \n",
    "                # Verify shape is correct\n",
    "                assert img_array.shape == (IMG_HEIGHT, IMG_WIDTH, 3), f\"Incorrect shape for {img_file}: {img_array.shape}\"\n",
    "                \n",
    "                # Load annotation\n",
    "                json_file = img_file.replace('.png', '.json')\n",
    "                json_path = os.path.join(self.image_dir, json_file)\n",
    "                with open(json_path, 'r') as f:\n",
    "                    annotation = json.load(f)\n",
    "                \n",
    "                boxes, classes, mask = parse_annotation(annotation)\n",
    "                \n",
    "                images.append(img_array)\n",
    "                all_boxes.append(boxes)\n",
    "                all_classes.append(classes)\n",
    "                all_masks.append(mask)\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        images = np.array(images)\n",
    "        all_boxes = np.array(all_boxes)\n",
    "        all_classes = np.array(all_classes)\n",
    "        all_masks = np.array(all_masks)\n",
    "        \n",
    "        print(f\"Loaded {len(images)} images with shape {images.shape}\")\n",
    "        \n",
    "        return images, all_boxes, all_classes, all_masks\n",
    "    \n",
    "    def create_tf_dataset(self, images, boxes, classes, masks):\n",
    "        \"\"\"Create a tf.data.Dataset with batching and shuffling\"\"\"\n",
    "        # Convert classes to one-hot encoding\n",
    "        classes_one_hot = tf.keras.utils.to_categorical(classes, num_classes=NUM_CLASSES)\n",
    "        \n",
    "        # Combine targets\n",
    "        y = np.concatenate([\n",
    "            boxes,\n",
    "            classes_one_hot,\n",
    "            np.expand_dims(masks, -1)\n",
    "        ], axis=-1)\n",
    "        \n",
    "        # Create dataset\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((images, y))\n",
    "        dataset = dataset.shuffle(1000)\n",
    "        dataset = dataset.batch(self.batch_size)\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2):\n",
    "    \"\"\"Compute IOU between two sets of boxes\"\"\"\n",
    "    # Calculate intersection coordinates\n",
    "    x1 = tf.maximum(boxes1[..., 0], boxes2[..., 0])\n",
    "    y1 = tf.maximum(boxes1[..., 1], boxes2[..., 1])\n",
    "    x2 = tf.minimum(boxes1[..., 2], boxes2[..., 2])\n",
    "    y2 = tf.minimum(boxes1[..., 3], boxes2[..., 3])\n",
    "    \n",
    "    # Calculate area of intersection\n",
    "    intersection = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
    "    \n",
    "    # Calculate area of both boxes\n",
    "    area1 = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    area2 = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "    \n",
    "    # Calculate IoU\n",
    "    union = area1 + area2 - intersection\n",
    "    iou = intersection / (union + tf.keras.backend.epsilon())\n",
    "    \n",
    "    return iou\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"Custom loss function using IoU for bounding boxes\"\"\"\n",
    "    # Unpack the true values\n",
    "    true_boxes = y_true[:, :, :4]\n",
    "    true_classes = y_true[:, :, 4:-1]\n",
    "    true_mask = y_true[:, :, -1]\n",
    "    \n",
    "    # Unpack predictions\n",
    "    pred_boxes = y_pred[:, :, :4]\n",
    "    pred_classes = y_pred[:, :, 4:-1]\n",
    "    pred_objectness = y_pred[:, :, -1]\n",
    "    \n",
    "    # Box loss using IoU\n",
    "    iou = compute_iou(true_boxes, pred_boxes)\n",
    "    box_loss = 1 - iou\n",
    "    box_loss = tf.reduce_mean(box_loss * true_mask)\n",
    "    \n",
    "    # Class loss\n",
    "    class_loss = tf.keras.losses.categorical_crossentropy(\n",
    "        true_classes, pred_classes, from_logits=True)\n",
    "    class_loss = tf.reduce_mean(class_loss * true_mask)\n",
    "    \n",
    "    # Objectness loss\n",
    "    obj_loss = tf.keras.losses.binary_crossentropy(\n",
    "        true_mask, pred_objectness, from_logits=True)\n",
    "    obj_loss = tf.reduce_mean(obj_loss)\n",
    "    \n",
    "    return box_loss + class_loss + obj_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Create dataset\n",
    "    dataset = ObjectDetectionDataset(IMAGE_DIR)\n",
    "    images, boxes, classes, masks = dataset.load_data()\n",
    "    \n",
    "    # Split into train and validation\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    (X_train, X_val, \n",
    "     boxes_train, boxes_val,\n",
    "     classes_train, classes_val,\n",
    "     masks_train, masks_val) = train_test_split(\n",
    "        images, boxes, classes, masks, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create tf.data.Datasets\n",
    "    train_dataset = dataset.create_tf_dataset(\n",
    "        X_train, boxes_train, classes_train, masks_train)\n",
    "    val_dataset = dataset.create_tf_dataset(\n",
    "        X_val, boxes_val, classes_val, masks_val)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = create_model()\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss=custom_loss\n",
    "    )\n",
    "    \n",
    "    # Training callbacks\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            'best_model.h5',\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss',\n",
    "            save_freq=100\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            patience=10,\n",
    "            monitor='val_loss'\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            factor=0.1,\n",
    "            patience=5,\n",
    "            monitor='val_loss'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=100,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
