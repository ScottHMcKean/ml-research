{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5374a922-bd4d-47c2-9782-ae3370c18db2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "\n",
    "def parse_annotation(annotation_path, image_dir):\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    image_path = os.path.join(image_dir, data['file_name'])\n",
    "    boxes = tf.convert_to_tensor(data['objects']['bbox'], dtype=tf.float32)\n",
    "    classes = tf.convert_to_tensor(data['objects']['category'], dtype=tf.int32)\n",
    "    \n",
    "    return image_path, boxes, classes\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, [300, 300])  # Resize to a fixed size\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "def create_example(annotation_path, image_dir):\n",
    "    image_path, boxes, classes = parse_annotation(annotation_path, image_dir)\n",
    "    image = load_and_preprocess_image(image_path)\n",
    "    return image, (boxes, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5004c30-9c16-42b4-9c0c-a4b431405e49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset(annotation_dir, image_dir, batch_size):\n",
    "    annotation_files = [\n",
    "      os.path.join(annotation_dir, f) \n",
    "      for f in os.listdir(annotation_dir) \n",
    "      if f.endswith('.json')\n",
    "      ][0:100]\n",
    "    \n",
    "    def generator():\n",
    "        for annotation_file in annotation_files:\n",
    "            yield create_example(annotation_file, image_dir)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_types=(tf.float32, (tf.float32, tf.int32)),\n",
    "        output_shapes=((300, 300, 3), ((None, 4), (None,)))\n",
    "    )\n",
    "    \n",
    "    dataset = dataset.shuffle(buffer_size=100)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset\n",
    "  \n",
    "# Usage\n",
    "train_dataset = create_dataset(\n",
    "  '/Volumes/shm/default/cppe5/annotations/', \n",
    "  '/Volumes/shm/default/cppe5/images/', \n",
    "  batch_size=10\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72db0490-7545-41d6-9839-7df29d9e931f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_object_detection_model(input_shape, num_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Convolutional layers\n",
    "    x = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D()(x)\n",
    "    x = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D()(x)\n",
    "    x = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D()(x)\n",
    "    \n",
    "    # Flatten and dense layers\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    \n",
    "    # Output layers\n",
    "    class_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='class_output')(x)\n",
    "    bbox_output = tf.keras.layers.Dense(4, name='bbox_output')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=[class_output, bbox_output])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_object_detection_model((300, 300, 3), num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7109e930-f579-48b2-8a6f-b4a941ddd090",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_fn(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for images, (boxes, classes) in train_dataset:\n",
    "        loss = train_step(images, classes)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01c9539a-03a6-4fd6-90bf-59e45afc9d07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for images, (boxes, classes) in train_dataset:\n",
    "    print(len(images))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "tensorflow_cppe_example",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
