{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5213a286-11a9-4999-b7e9-52c7522585b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install catboost shap scikit-learn mlflow --upgrade\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1521acc-9a6e-45cd-a083-e44544c027d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import shap\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# added catboost\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44093a9b-bcf3-4b8b-873f-728072a9023f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Scikit Learn Pseudocode Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e500b5f-82ed-4cd5-9b2e-b915626b21bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 0. Read the csv into a pandas df\n",
    "df = pd.read_parquet('./fake_sku_data.parquet')\n",
    "\n",
    "## PSEUDOCODE FOR PUSHING DATA PROCESSING INTO SPARK ##\n",
    "# df = spark.table(cat.sch.table).filter(region == 'X').orderBY(F.rand()).limit(1000000).toPandas()\n",
    "\n",
    "\n",
    "# df = spark.sql(f\"\"\"\n",
    "#   SELECT * FROM data_table\n",
    "#   WHERE sku in ({sku_list})\n",
    "# \"\").filter(f\"sku IN ()\").orderBY(F.rand()).limit(1000000).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6c13dd8-2e69-429f-b2b7-9fd3cfb7f6fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. StringIndex categorical columns (Label Encoding or OneHotEncoding for sklearn)\n",
    "categorical_cols = [\n",
    "    'store_id', 'product_id', 'store_size', 'province', 'region_name',\n",
    "    'area_name', 'zone_id', 'zone_desc', 'category_id',\n",
    "    'category_name', 'product_desc', 'province_simple', 'region_simple', 'location_type', 'urban_rural'\n",
    "]\n",
    "numerical_cols = [col for col in df.columns if col not in categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7bc6051-bc72-4447-80b0-46f3bb3fadcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Assemble features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "        ('num', 'passthrough', numerical_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02dee79b-1a0b-4ffe-af63-6c55fcd06519",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Random Forest\n",
    "rf = RandomForestRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3006918-a57f-42d1-987c-197bf3575262",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Full pipeline: indexers + assembler + regressor\n",
    "pipeline = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('regressor', rf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f3fdae1-d990-476f-8eac-c38cddecc8a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter top 120 by rank (sku_r12_sales_ratio_rank)\n",
    "filtered_df = df[df['sku_sales_ratio_rank'] <= 120]\n",
    "X = filtered_df[categorical_cols + numerical_cols]\n",
    "y = filtered_df['units_sold_period']\n",
    "\n",
    "# 5. Union the test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b1f8925-f470-4233-9351-eac807b71dc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Let's activate autologging ##\n",
    "import mlflow\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# 6. Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200],\n",
    "    'regressor__max_depth': [3, 5]\n",
    "}\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e40308c9-b0cd-4c05-bd6d-6b8a13f45e73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 7. Evaluate on train set\n",
    "train_preds = grid.predict(X_train)\n",
    "print('Train RMSE:', np.sqrt(mean_squared_error(y_train, train_preds)))\n",
    "print('Train R2:', r2_score(y_train, train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce549823-eff7-4881-a4f1-5cc504432bea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_preds = grid.predict(X_test)\n",
    "print('Train RMSE:', np.sqrt(mean_squared_error(y_test, test_preds)))\n",
    "print('Train R2:', r2_score(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21c57ae1-2cb2-46ad-ba9f-cbaeed23dce9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# An example of reloading the model\n",
    "reload_model = mlflow.sklearn.load_model('models:/shm.default.sku_model@current')\n",
    "reload_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f06bd5cc-37d1-47f4-ac32-3bf24f3fec57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 8. Show predictions\n",
    "test_preds = grid.predict(X_test)\n",
    "print(test_preds[:10])  # Show first 10 preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3afcce2b-2350-4623-8440-9623b04ce903",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 9. Re-create and fit the model with the best parameters\n",
    "best_pipeline = grid.best_estimator_\n",
    "best_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e50ba78a-aa6b-4d65-bc87-c97fd8a40412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# New - set custom params\n",
    "pipeline.set_params(\n",
    "    regressor__n_estimators=100,\n",
    "    regressor__max_depth=10\n",
    ")\n",
    "pipeline.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eddbab24-7b59-46f3-ae7b-cf494300ddb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 10. Use same indexers and assembler as before (already done above)\n",
    "# 11. Get feature importances\n",
    "rf_model = best_pipeline.named_steps['regressor']\n",
    "importances = rf_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fbc6e41-d864-496b-8780-ba7140691389",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 12. Map importances to feature names\n",
    "feature_names = (\n",
    "    best_pipeline.named_steps['preproc']\n",
    "    .transformers_[0][1]\n",
    "    .get_feature_names_out(categorical_cols)\n",
    "    .tolist()\n",
    "    + numerical_cols\n",
    ")\n",
    "\n",
    "indices = np.argsort(importances)[::-1][:10]  # Indices of top 10 importances\n",
    "\n",
    "top_features = [feature_names[i] for i in indices]\n",
    "top_importances = [importances[i] for i in indices]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(top_features, top_importances, color='skyblue')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top 10 Feature Importances from Random Forest Model')\n",
    "plt.gca().invert_yaxis()  # Most important at the top\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c17c550-7856-4806-bf00-d8d92c1d90ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## SHAP Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "374395d7-cd08-4725-acef-0e050bd0b525",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sample 100 rows from X_test for SHAP\n",
    "X_sample = X_test.sample(100, random_state=42)\n",
    "\n",
    "# Transform data as pipeline does\n",
    "X_transformed = best_pipeline.named_steps['preproc'].transform(X_sample)\n",
    "\n",
    "# Ensure data is pure float\n",
    "X_transformed = X_transformed.astype(np.float32, casting='unsafe')\n",
    "\n",
    "# Run SHAP as before\n",
    "explainer = shap.TreeExplainer(best_pipeline.named_steps['regressor'])\n",
    "shap_values = explainer.shap_values(X_transformed)\n",
    "shap.summary_plot(shap_values, X_transformed, feature_names=feature_names, max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6324ef24-e1e5-4deb-bf09-59097fcded71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "index_of_total_ppl = list(X.columns).index('total_ppl')\n",
    "\n",
    "# Use original feature names from after preprocessing if possible, otherwise use column index\n",
    "shap.dependence_plot(\n",
    "    index_of_total_ppl,            # index of total_ppl\n",
    "    shap_values,\n",
    "    X_transformed,\n",
    "    feature_names=list(X.columns)  # for correct labeling\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0037988f-ea8f-4483-a773-73ec0e8fd6e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Catboost\n",
    "We can also use a Catboost model and bring the whole workflow together. The hardest part of Catboost is avoiding it overfitting too much!! But it is going to crush LightGBM or Random Forest 95% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a105dec7-cdbd-40f8-844c-009e53726957",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.autolog()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Build pipeline: preprocess + CatBoost\n",
    "    model = CatBoostRegressor(\n",
    "      iterations=100, \n",
    "      learning_rate=0.1, \n",
    "      depth=3, \n",
    "      verbose=0,\n",
    "      cat_features=categorical_cols)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    print('Test RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print('Test R2:', r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "train_sklearn",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
